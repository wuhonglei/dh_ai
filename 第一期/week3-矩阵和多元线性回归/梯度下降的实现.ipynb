{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_x(x, w):\n",
    "    \"\"\" 预测函数 \"\"\"\n",
    "    sum = 0\n",
    "    for i in range(len(w)):\n",
    "        sum += w[i] * x[i]\n",
    "\n",
    "    return sum\n",
    "\n",
    "\n",
    "def gradient_w(x, y, w):\n",
    "    \"\"\" 梯度函数 \"\"\"\n",
    "    gradients = []\n",
    "    for i in range(len(w)):\n",
    "        sum = 0\n",
    "        for j in range(len(x)):\n",
    "            sum += (f_x(x[j], w) - y[j]) * x[j][i]\n",
    "        gradients.append(sum / len(x))\n",
    "    return gradients\n",
    "\n",
    "\n",
    "def loss(x, y, w):\n",
    "    \"\"\" 损失函数 \"\"\"\n",
    "    sum = 0\n",
    "    for i in range(len(x)):\n",
    "        sum += (f_x(x[i], w) - y[i]) ** 2\n",
    "    return sum / (2 * len(x))\n",
    "\n",
    "\n",
    "def gradient_descent(x, y, w, alpha, n):\n",
    "    \"\"\" 梯度下降函数 \"\"\"\n",
    "    for i in range(n):\n",
    "        gradients = gradient_w(x, y, w)\n",
    "        for j in range(len(w)):\n",
    "            w[j] -= alpha * gradients[j]\n",
    "        # if i % 100 == 0:\n",
    "        #     print(\"w: \",  w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.053239363104949124, 2.973632491838992, 0.36453714531297854, 0.19622315864578532, -0.19885713569982533]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 40.55954234716471)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\n",
    "    [1, 96.79, 2, 1, 2],\n",
    "    [1, 110.39, 3, 1, 0],\n",
    "    [1, 70.25, 1, 0, 2],\n",
    "    [1, 99.96, 2, 1, 1],\n",
    "    [1, 118.15, 3, 1, 0],\n",
    "    [1, 115.08, 3, 1, 2]\n",
    "]\n",
    "y = [287, 343, 199, 298, 340, 350]\n",
    "w = [0, 0, 0, 0, 0]\n",
    "alpha = 0.00001\n",
    "n = 15000\n",
    "w = gradient_descent(x, y, w, alpha, n)\n",
    "print(w), loss(x, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 288.292, real: 287\n",
      "predict: 329.496, real: 343\n",
      "predict: 208.811, real: 199\n",
      "predict: 297.918, real: 298\n",
      "predict: 352.571, real: 340\n",
      "predict: 343.045, real: 350\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x)):\n",
    "    h = f_x(x[i], w)\n",
    "    print(f\"predict: {h:.3f}, real: {y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(x):\n",
    "    \"\"\" 计算特征的平均值 \"\"\"\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "\n",
    "def stand_deviation(x, avg):\n",
    "    \"\"\" 计算特征的标准差 \"\"\"\n",
    "    sum = 0\n",
    "    m = len(x)\n",
    "    for i in x:\n",
    "        sum += (i - avg) ** 2\n",
    "\n",
    "    return (sum / (m - 1)) ** 0.5\n",
    "\n",
    "\n",
    "def normalization(x):\n",
    "    \"\"\" 特征归一化 \"\"\"\n",
    "    m = len(x)\n",
    "    n = len(x[0])\n",
    "    avgs = []\n",
    "    sds = []\n",
    "    for column_index in range(1, n):\n",
    "        features = [x[row_index][column_index] for row_index in range(m)]\n",
    "        avg = average(features)\n",
    "        sd = stand_deviation(features, avg)\n",
    "        avgs.append(avg)\n",
    "        sds.append(sd)\n",
    "        for row_index in range(m):\n",
    "            x[row_index][column_index] = (\n",
    "                x[row_index][column_index] - avg) / sd\n",
    "    return x, avgs, sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[302.83333333333053, 35.768216959196394, 21.084325397086545]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 25.690331152482486)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = [\n",
    "    [1, 9679, 2],\n",
    "    [1, 11039, 3],\n",
    "    [1, 7025, 1],\n",
    "    [1, 9996, 2],\n",
    "    [1, 11815, 3],\n",
    "    [1, 11508, 3]\n",
    "]\n",
    "x1, avgs, sds = normalization(x1)\n",
    "y1 = [287, 343, 199, 298, 340, 350]\n",
    "w1 = [0, 0, 0]\n",
    "alpha1 = 0.01\n",
    "n1 = 150000\n",
    "w1 = gradient_descent(x1, y1, w1, alpha1, n1)\n",
    "print(w1), loss(x1, y1, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, -0.2836373753520578, -0.4082482904638632],\n",
       " [1, 0.49095465372183494, 0.8164965809277258],\n",
       " [1, -1.7952309379712572, -1.6329931618554523],\n",
       " [1, -0.10308908622233426, -0.4082482904638632],\n",
       " [1, 0.9329277526639973, 0.8164965809277258],\n",
       " [1, 0.7580749931598171, 0.8164965809277258]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 340.889\n",
      "predict: 336.815\n"
     ]
    }
   ],
   "source": [
    "test1 = [1, 11200, 3]\n",
    "test2 = [1, 11000, 3]\n",
    "\n",
    "\n",
    "def normalization_test(test, avgs, sds):\n",
    "    for i in range(1, len(test)):\n",
    "        test[i] = (test[i] - avgs[i - 1]) / sds[i - 1]\n",
    "    return test\n",
    "\n",
    "\n",
    "new_test1 = normalization_test(test1, avgs, sds)\n",
    "new_test2 = normalization_test(test2, avgs, sds)\n",
    "print(f\"predict: {f_x(new_test1, w1):.3f}\")\n",
    "print(f\"predict: {f_x(new_test2, w1):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
