loading cache from ./cache/data/sg_1757971_1731660759_csv.pkl
loading json from ./config/SG/SG_label_to_index.json
saving json to ./config/SG/SG_label_to_index.json
/mnt/nlp/dh_ai/课后作业/关键词分类_pytorch/模型改进_only_keyword/dataset.py:54: FutureWarning: The behavior of Index.insert with object-dtype is deprecated, in a future version this will return an object-dtype Index instead of inferring a non-object dtype. To retain the old behavior, do `idx.insert(loc, item).infer_objects(copy=False)`
  one_hot_encoded_df = pd.get_dummies(sub_category, dummy_na=True)
saving cache to ./cache/tokennizer/SG_0_d41d8cd98f00b204e9800998ecf8427e.pkl
Traceback (most recent call last):
  File "/mnt/nlp/dh_ai/课后作业/关键词分类_pytorch/模型改进_only_keyword/main.py", line 46, in <module>
    train(X, sub_y, y, country)
  File "/mnt/nlp/dh_ai/课后作业/关键词分类_pytorch/模型改进_only_keyword/train.py", line 27, in train
    train_dataset, test_dataset = train_test_split(
  File "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/sklearn/model_selection/_split.py", line 2785, in train_test_split
    n_train, n_test = _validate_shuffle_split(
  File "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/sklearn/model_selection/_split.py", line 2415, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=0, test_size=0.05 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
