{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始列表 a: [1, 2, ['X', 4]]\n",
      "浅复制 b: [1, 2, ['X', 4]]\n",
      "深度复制 c: [1, 2, [3, 4]]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# 创建一个包含列表的列表\n",
    "a = [1, 2, [3, 4]]\n",
    "\n",
    "# 浅复制\n",
    "b = copy.copy(a)\n",
    "\n",
    "# 深度复制\n",
    "c = copy.deepcopy(a)\n",
    "\n",
    "# 修改原始列表中的嵌套列表\n",
    "a[2][0] = 'X'\n",
    "\n",
    "print(\"原始列表 a:\", a)\n",
    "print(\"浅复制 b:\", b)\n",
    "print(\"深度复制 c:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([\n",
    "    [1, 2]\n",
    "])\n",
    "\n",
    "b = torch.nn.Conv1d(1, 1, 1)\n",
    "\n",
    "c = b(a)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([\n",
    "    [1, 2, 3, 4, 5, 6]\n",
    "])\n",
    "\n",
    "x1, x2 = a.split(3, dim=1)\n",
    "\n",
    "print(x1.shape)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单个 768x768 矩阵转置时间：0.000127 秒\n",
      "三个 768x256 矩阵转置时间：0.000133 秒\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# 情况 1：768 x 768 的单个矩阵\n",
    "matrix1 = torch.randn(768, 768)\n",
    "\n",
    "start_time = time.time()\n",
    "matrix1_T = matrix1.T  # 转置操作\n",
    "time1 = time.time() - start_time\n",
    "\n",
    "# 情况 2：768 x 256 的 3 个矩阵\n",
    "matrix2_1 = torch.randn(768, 256)\n",
    "matrix2_2 = torch.randn(768, 256)\n",
    "matrix2_3 = torch.randn(768, 256)\n",
    "\n",
    "start_time = time.time()\n",
    "matrix2_1_T = matrix2_1.T  # 第一个矩阵的转置\n",
    "matrix2_2_T = matrix2_2.T  # 第二个矩阵的转置\n",
    "matrix2_3_T = matrix2_3.T  # 第三个矩阵的转置\n",
    "time2 = time.time() - start_time\n",
    "\n",
    "# 输出结果\n",
    "print(f\"单个 768x768 矩阵转置时间：{time1:.6f} 秒\")\n",
    "print(f\"三个 768x256 矩阵转置时间：{time2:.6f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "梯度1-w tensor([[ 0.3127, -0.0082],\n",
      "        [-0.3650, -0.1062]])\n",
      "梯度1-b tensor([ 0.6028, -0.5385])\n",
      "梯度2-w tensor([[ 0.3127, -0.0082],\n",
      "        [-0.3650, -0.1062]])\n",
      "梯度2-b tensor([ 0.6028, -0.5385])\n",
      "---\n",
      "更新后的w1 Parameter containing:\n",
      "tensor([[-0.1656,  0.2504],\n",
      "        [ 0.2653,  0.3041]], requires_grad=True)\n",
      "更新后的w2 Parameter containing:\n",
      "tensor([[-0.1656,  0.2504],\n",
      "        [ 0.2653,  0.3041]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 帮我写一个 pytorch 反向传播的最简单示例\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义一个简单的线性模型\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 2)\n",
    "        self.linear2 = nn.Linear(2, 2)\n",
    "        self.linear3 = nn.Linear(2, 1)\n",
    "        self.linear2.weight = self.linear1.weight\n",
    "        self.linear2.bias = self.linear1.bias\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleModel()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 生成一些示例数据\n",
    "x = torch.randn(10, 2)\n",
    "y = torch.randn(10, 1)\n",
    "\n",
    "# 前向传播\n",
    "output = model(x)\n",
    "loss = criterion(output, y)\n",
    "\n",
    "# 反向传播\n",
    "loss.backward()\n",
    "\n",
    "print('梯度1-w', model.linear1.weight.grad)\n",
    "print('梯度1-b', model.linear1.bias.grad)\n",
    "\n",
    "print('梯度2-w', model.linear2.weight.grad)\n",
    "print('梯度2-b', model.linear2.bias.grad)\n",
    "\n",
    "\n",
    "# 更新参数\n",
    "optimizer.step()\n",
    "\n",
    "print('---')\n",
    "print('更新后的w1', model.linear1.weight)\n",
    "print('更新后的w2', model.linear2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3])\n",
    "a.unsqueeze(0).repeat(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2]), tensor([1, 2], device='mps:0'))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from atexit import register\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    elif torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 2)\n",
    "        self.register_buffer('var_1', torch.tensor([1, 2]))\n",
    "        self.var = torch.tensor([1, 2], requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleModel()\n",
    "# apple mps device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.var, model.var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 2) + (3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.0000, 0.0000, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "top_k = 3\n",
    "logits = torch.tensor([[3, 2, 1, 4, 5]], dtype=torch.float32)\n",
    "values, indices = torch.topk(logits, k=top_k)\n",
    "tok_k_logits = torch.where(\n",
    "    logits < values[:, -1], torch.ones_like(logits) * -1e10, logits)\n",
    "F.softmax(tok_k_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "log_probs = torch.tensor([0.2, 0.3, 0.5])\n",
    "torch.multinomial(log_probs, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+09, -1.0000e+09, -1.0000e+09]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "b = torch.ones(1, 3)\n",
    "mask = a[:1, :1]\n",
    "b = b.masked_fill(mask == 0, -1e9)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.],\n",
       "        [16.]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audioop import bias\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "p = torch.nn.Parameter(torch.ones((3, 1), dtype=torch.float32))\n",
    "# 打印 p 的参数尺寸\n",
    "\n",
    "bias = torch.ones((1))\n",
    "\n",
    "torch.addmm(bias, a, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word </s>\n",
      "word <s>\n",
      "word <pad>\n",
      "word <unk>\n"
     ]
    }
   ],
   "source": [
    "vocab = set([\n",
    "    '<pad>',\n",
    "    '<s>',\n",
    "    '</s>',\n",
    "    '<unk>',\n",
    "])\n",
    "\n",
    "for word in vocab:\n",
    "    print('word', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "' \\n'.rstrip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
