{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '验证码识别', 'dataset': {'name': 'captcha', 'train_total': 10000, 'test_total': 1000, 'captcha_length': 1, 'width': 200, 'height': 100, 'characters': '0123456789', 'train_dir': 'data/train', 'test_dir': 'data/test'}, 'model': {'type': 'CNN', 'layers': 5, 'activation': 'relu'}, 'training': {'train_dir': 'data/train', 'batch_size': 128, 'learning_rate': 0.001, 'epochs': 50, 'evaluate': True, 'model_path': './model/model.pth'}, 'testing': {'test_dir': 'data/test', 'model_path': './model/model.pth'}}\n",
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# 打开并读取 YAML 文件\n",
    "with open('./config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# 输出解析后的 Python 字典\n",
    "print(config)\n",
    "\n",
    "# 访问特定配置项\n",
    "print(config['training']['evaluate'])  # 输出: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3020607335567473\n",
      "2.039491341948509\n",
      "1.0194213927821256\n",
      "0.5158141216741351\n",
      "0.3220077866648753\n",
      "0.2706733280072217\n",
      "0.18498209164651813\n",
      "0.1611229153689681\n",
      "Counter: 1\n",
      "0.17335387797373533\n",
      "0.1459376681901153\n",
      "0.14415635538482297\n",
      "0.13065030967203936\n",
      "0.10870517556085056\n",
      "0.09841014109749086\n",
      "Counter: 1\n",
      "0.1151253210754164\n",
      "Counter: 2\n",
      "0.13909800600919955\n",
      "Counter: 3\n",
      "0.10651186918238796\n",
      "Counter: 4\n",
      "0.10578753057510773\n",
      "Counter: 5\n",
      "Early stopping..., epoch: 18\n"
     ]
    }
   ],
   "source": [
    "loss_list = [2.3020607335567473, 2.039491341948509, 1.0194213927821256, 0.5158141216741351, 0.3220077866648753, 0.2706733280072217, 0.18498209164651813, 0.1611229153689681, 0.17335387797373533,\n",
    "             0.1459376681901153, 0.14415635538482297, 0.13065030967203936, 0.10870517556085056, 0.09841014109749086, 0.1151253210754164, 0.13909800600919955, 0.10651186918238796, 0.10578753057510773, 0.13021349731665155]\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.0001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        elif self.best_loss - loss > self.delta:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print('Counter:', self.counter)\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        return self.early_stop\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "for epoch, loss in enumerate(loss_list):\n",
    "    if early_stopping(loss):\n",
    "        print('Early stopping..., epoch:', epoch)\n",
    "        break\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensor(1, dtype=torch.uint8)tensor(2, dtype=torch.uint8)tensor(3, dtype=torch.uint8)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "''.join(map(str, torch.tensor(list(map(int, '123')),  dtype=torch.uint8).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'view_as'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m     22\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m     23\u001b[0m     [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m],\n\u001b[1;32m     24\u001b[0m     [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m]\n\u001b[1;32m     25\u001b[0m ])\n\u001b[1;32m     27\u001b[0m predict \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m(predict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'view_as'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ],\n",
    "    [\n",
    "        [10, 11, 12],\n",
    "        [13, 14, 15],\n",
    "        [16, 17, 18]\n",
    "    ],\n",
    "    [\n",
    "        [19, 20, 21],\n",
    "        [22, 23, 24],\n",
    "        [25, 26, 27]\n",
    "    ]\n",
    "])\n",
    "\n",
    "b = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "predict = a.argmax(axis=2, keepdims=True)\n",
    "b.view_as(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([\n",
    "    [True, False, False],\n",
    "    [True, True, False],\n",
    "    [True, True, False]\n",
    "])\n",
    "np.any(a, axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "a.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6590, 0.2424, 0.0986],\n",
      "        [0.1131, 0.8360, 0.0508]])\n",
      "tensor(0.2981)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建 CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 假设模型输出 logits，形状为 (batch_size, num_classes)\n",
    "logits = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],\n",
    "    [1.0, 3.0, 0.2]\n",
    "])\n",
    "\n",
    "# 计算 softmax\n",
    "probs = nn.functional.softmax(logits, dim=1)\n",
    "print(probs)\n",
    "\n",
    "# 假设真实标签，形状为 (batch_size,)\n",
    "targets = torch.tensor([0, 1])  # 第一个样本真实类别为 0，第二个样本真实类别为 1\n",
    "\n",
    "# 计算交叉熵损失\n",
    "loss = criterion(logits, targets)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 23\u001b[0m\n\u001b[1;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m])  \u001b[38;5;66;03m# 真实标签\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 计算损失\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# loss = bce_loss(preds, labels)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(loss.item())\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 计算交叉熵损失\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Desktop/人工智能/python/dh_ai/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/人工智能/python/dh_ai/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/人工智能/python/dh_ai/myenv/lib/python3.9/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/人工智能/python/dh_ai/myenv/lib/python3.9/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建 Binary Cross-Entropy Loss\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "# 创建 CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLossWithLogits()\n",
    "\n",
    "# 假设模型的预测概率为 (batch_size,)\n",
    "preds = torch.tensor([\n",
    "    [0.9, 0.1],\n",
    "    [0.2, 0.8],\n",
    "    [0.7, 0.3]\n",
    "])  # 模型预测的概率\n",
    "labels = torch.tensor([1.0, 0.0, 1.0])  # 真实标签\n",
    "\n",
    "# 计算损失\n",
    "# loss = bce_loss(preds, labels)\n",
    "# print(loss.item())\n",
    "\n",
    "# 计算交叉熵损失\n",
    "loss = criterion(preds, labels)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2, 2),\n",
       " array([[ 5,  7],\n",
       "        [ 9, 11]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array(\n",
    "    [\n",
    "        [\n",
    "            [1, 2],\n",
    "            [3, 4]\n",
    "        ],\n",
    "        [\n",
    "            [4, 5],\n",
    "            [6, 7]\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "a.shape, a.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from captcha.image import ImageCaptcha\n",
    "\n",
    "chars = '9'\n",
    "captcha = ImageCaptcha(width=200, height=100)\n",
    "img = captcha.generate_image(chars)\n",
    "# captcha.create_noise_dots(img, '#000000', 4, 40)  # type: ignore\n",
    "# captcha.create_noise_curve(img, '#000000')  # type: ignore\n",
    "img.save('./9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [0., 1., 0.]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LocalizationNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LocalizationNetwork, self).__init__()\n",
    "\n",
    "        # 定义卷积层\n",
    "        # 1 个输入通道, 16 个输出通道, 7x7 卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=7)\n",
    "        # 16 个输入通道, 32 个输出通道, 5x5 卷积核\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        # 32 个输入通道, 64 个输出通道, 5x5 卷积核\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "\n",
    "        # 全连接层，用于输出仿射变换的参数 (2x3)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # 计算卷积层输出的特征图大小后设置全连接层的输入大小\n",
    "        self.fc2 = nn.Linear(128, 6)  # 输出 6 个仿射变换参数 (2x3 矩阵)\n",
    "\n",
    "        # 初始化仿射变换为单位矩阵\n",
    "        self.fc2.weight.data.zero_()\n",
    "        self.fc2.bias.data.copy_(torch.tensor(\n",
    "            [1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 卷积层 + 池化\n",
    "        # 输入: (128x128), 输出: (61x61)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))  # 输入: (61x61), 输出: (29x29)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))  # 输入: (29x29), 输出: (12x12)\n",
    "\n",
    "        # 展平为全连接层输入\n",
    "        x = x.view(-1, 64 * 12 * 12)\n",
    "\n",
    "        # 全连接层\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # 输出仿射变换参数\n",
    "        theta = self.fc2(x)\n",
    "        theta = theta.view(-1, 2, 3)  # 输出 2x3 仿射矩阵\n",
    "        return theta\n",
    "\n",
    "\n",
    "model = LocalizationNetwork()\n",
    "x = torch.randn(1, 1, 128, 128)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1725928990"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# 将时间戳浮点数转换为 10 位整形时间戳\n",
    "int(time.time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
