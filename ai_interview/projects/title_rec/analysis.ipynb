{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡ä»¶: ./dataset/csv/test.csv\n",
      "æ•°æ®é‡: 13722\n",
      "æ•°æ®é‡å æ¯”: 5.00%\n",
      "åˆ—æ•°: 10\n",
      "åˆ—å: ['name', 'global_be_category_id', 'global_be_category', 'global_be_category_level', 'level1_global_be_category_id', 'level2_global_be_category_id', 'level3_global_be_category_id', 'level4_global_be_category_id', 'main_image', 'attached_images']\n",
      "æ•°æ®ç±»å‹: name                             object\n",
      "global_be_category_id             int64\n",
      "global_be_category               object\n",
      "global_be_category_level          int64\n",
      "level1_global_be_category_id      int64\n",
      "level2_global_be_category_id      int64\n",
      "level3_global_be_category_id    float64\n",
      "level4_global_be_category_id    float64\n",
      "main_image                       object\n",
      "attached_images                  object\n",
      "dtype: object\n",
      "************************************************åˆ†å‰²çº¿*************************************************\n",
      "æ–‡ä»¶: ./dataset/csv/train.csv\n",
      "æ•°æ®é‡: 246980\n",
      "æ•°æ®é‡å æ¯”: 90.00%\n",
      "åˆ—æ•°: 10\n",
      "åˆ—å: ['name', 'global_be_category_id', 'global_be_category', 'global_be_category_level', 'level1_global_be_category_id', 'level2_global_be_category_id', 'level3_global_be_category_id', 'level4_global_be_category_id', 'main_image', 'attached_images']\n",
      "æ•°æ®ç±»å‹: name                             object\n",
      "global_be_category_id             int64\n",
      "global_be_category               object\n",
      "global_be_category_level          int64\n",
      "level1_global_be_category_id      int64\n",
      "level2_global_be_category_id      int64\n",
      "level3_global_be_category_id    float64\n",
      "level4_global_be_category_id    float64\n",
      "main_image                       object\n",
      "attached_images                  object\n",
      "dtype: object\n",
      "************************************************åˆ†å‰²çº¿*************************************************\n",
      "æ–‡ä»¶: ./dataset/csv/val.csv\n",
      "æ•°æ®é‡: 13721\n",
      "æ•°æ®é‡å æ¯”: 5.00%\n",
      "åˆ—æ•°: 10\n",
      "åˆ—å: ['name', 'global_be_category_id', 'global_be_category', 'global_be_category_level', 'level1_global_be_category_id', 'level2_global_be_category_id', 'level3_global_be_category_id', 'level4_global_be_category_id', 'main_image', 'attached_images']\n",
      "æ•°æ®ç±»å‹: name                             object\n",
      "global_be_category_id             int64\n",
      "global_be_category               object\n",
      "global_be_category_level          int64\n",
      "level1_global_be_category_id      int64\n",
      "level2_global_be_category_id      int64\n",
      "level3_global_be_category_id    float64\n",
      "level4_global_be_category_id    float64\n",
      "main_image                       object\n",
      "attached_images                  object\n",
      "dtype: object\n",
      "************************************************åˆ†å‰²çº¿*************************************************\n"
     ]
    }
   ],
   "source": [
    "# 1. åˆ†ææ•°æ®é‡\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "csv_paths = ['./dataset/csv/test.csv',\n",
    "             './dataset/csv/train.csv', './dataset/csv/val.csv']\n",
    "total = 274423\n",
    "\n",
    "for csv_path in csv_paths:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"æ–‡ä»¶: {csv_path}\")\n",
    "    print(f\"æ•°æ®é‡: {len(df)}\")\n",
    "    print(f\"æ•°æ®é‡å æ¯”: {len(df)/total:.2%}\")\n",
    "    print(f\"åˆ—æ•°: {len(df.columns)}\")\n",
    "    print(f\"åˆ—å: {df.columns.tolist()}\")\n",
    "    print(f\"æ•°æ®ç±»å‹: {df.dtypes}\")\n",
    "    print(f'{\"åˆ†å‰²çº¿\":*^100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡ä»¶: ./dataset/csv/val.csv\n",
      "St.kunkka Round Key Ring - Gold/Silver (10 Pcs/Lot 25 X 28 X 30mm) --- æ—¶å°šé…é¥°\n",
      "Korean Retro Folds Love Heart Silicone Soft Phone Case For IPhone 12 11 13 14 Pro Max 11 12 13 14 Luxury Shockproof Back Cover --- æ‰‹æœºå¹³æ¿ä¸é…ä»¶\n",
      "ã€SG Local Stockã€‘Buy 4 get 1 free - Disposable Kitchen Wipes Extra Large Wet Wipes Floor Wipes 60 and 80pc type --- å®¶å±…ç”Ÿæ´»\n",
      "Blue Light Blocking Eyeglasses for Women and Men - Fashionable Round Frames for Optical and Computer Use - Protect Your Eyes from Harmful Blue Light --- æ—¶å°šé…é¥°\n",
      "ğŸ‡¸ğŸ‡¬ã€SG stockã€‘Air Fryer Paper Tray Air Fryer Disposable Paper Liner Oilproof Baking Paper Air Fryer Oilproof Parchment --- å®¶å±…ç”Ÿæ´»\n",
      "[SG SELLER] Children Kids Boys bow tie Bowtie Child --- æ—¶å°šé…é¥°\n",
      "Tea Bag Storage Box Drawer Type underTable CoffeeCapsule Finishing Box Acrylic Sealed with Lid Good-looking Storage Tank-Tea Bag Storage Box Coffee Bag Container Office Organiser --- å®¶å±…ç”Ÿæ´»\n",
      "face towel Korea DAMAH  Magic Disposable Cleaning Face Towel Multi-purpose Makeup Cotton 80sheets --- å®¶å±…ç”Ÿæ´»\n",
      "Waterproof Travel Portable Disposable Toilet Seat Covers --- å®¶å±…ç”Ÿæ´»\n",
      "Women Lazy People Large Capacity Sunflower False Eyelashes / Bushy Simulation Eyelash Extending Makeup Tool / Single Cluster False Eyelashes --- ç¾å¦†ä¿å¥\n",
      "************************************************åˆ†å‰²çº¿*************************************************\n",
      "è¯»å–æ—¶é—´: 0.08 ç§’\n"
     ]
    }
   ],
   "source": [
    "# éšæœºé‡‡æ ·ï¼ŒæŸ¥çœ‹æ ‡é¢˜å’Œç±»åˆ«\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from utils.category import load_category_list, category_list_to_dict\n",
    "category_list = load_category_list('./json/mtsku_category_tree.json')\n",
    "category_dict = category_list_to_dict(category_list)\n",
    "\n",
    "csv_paths = ['./dataset/csv/test.csv',\n",
    "             './dataset/csv/train.csv', './dataset/csv/val.csv']\n",
    "total = 274423\n",
    "target_index = 2\n",
    "\n",
    "start_time = time.time()\n",
    "for index, csv_path in enumerate(csv_paths):\n",
    "    if index != target_index:\n",
    "        continue\n",
    "\n",
    "    # è¯»å–æŒ‡å®šçš„å‡ åˆ—\n",
    "    df = pd.read_csv(csv_path, usecols=[\n",
    "                     'name', 'level1_global_be_category_id'])\n",
    "    print(f\"æ–‡ä»¶: {csv_path}\")\n",
    "    for index, row in df.sample(10).iterrows():\n",
    "        print(\n",
    "            f\"{row['name']} --- {category_dict[row['level1_global_be_category_id']]['display_name']}\")\n",
    "    print(f'{\"åˆ†å‰²çº¿\":*^100}')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"è¯»å–æ—¶é—´: {end_time - start_time:.2f} ç§’\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡ä»¶: ./dataset/csv/test.csv\n",
      "level1_global_be_category_id\n",
      "100636    5461\n",
      "100630    2849\n",
      "100629    2077\n",
      "100009    1687\n",
      "100013    1648\n",
      "Name: count, dtype: int64\n",
      "************************************************åˆ†å‰²çº¿*************************************************\n",
      "æ–‡ä»¶: ./dataset/csv/train.csv\n",
      "level1_global_be_category_id\n",
      "100636    98196\n",
      "100630    50629\n",
      "100629    38014\n",
      "100013    30226\n",
      "100009    29915\n",
      "Name: count, dtype: int64\n",
      "************************************************åˆ†å‰²çº¿*************************************************\n",
      "æ–‡ä»¶: ./dataset/csv/val.csv\n",
      "level1_global_be_category_id\n",
      "100636    5352\n",
      "100630    2866\n",
      "100629    2089\n",
      "100009    1727\n",
      "100013    1687\n",
      "Name: count, dtype: int64\n",
      "************************************************åˆ†å‰²çº¿*************************************************\n",
      "è¯»å–æ—¶é—´: 0.91 ç§’\n"
     ]
    }
   ],
   "source": [
    "# ç±»åˆ«è®¡æ•°\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from utils.category import load_category_list, category_list_to_dict\n",
    "category_list = load_category_list('./json/mtsku_category_tree.json')\n",
    "category_dict = category_list_to_dict(category_list)\n",
    "\n",
    "csv_paths = ['./dataset/csv/test.csv',\n",
    "             './dataset/csv/train.csv', './dataset/csv/val.csv']\n",
    "total = 274423\n",
    "target_index = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for index, csv_path in enumerate(csv_paths):\n",
    "    # if index != target_index:\n",
    "    #     continue\n",
    "\n",
    "    # è¯»å–æŒ‡å®šçš„å‡ åˆ—\n",
    "    df = pd.read_csv(csv_path, usecols=[\n",
    "                     'name', 'level1_global_be_category_id'])\n",
    "    print(f\"æ–‡ä»¶: {csv_path}\")\n",
    "    print(df['level1_global_be_category_id'].value_counts())\n",
    "    print(f'{\"åˆ†å‰²çº¿\":*^100}')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"è¯»å–æ—¶é—´: {end_time - start_time:.2f} ç§’\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
