Title: 一名985小硕的CV算法秋招面经和经历总结_牛客网

URL Source: https://www.nowcoder.com/discuss/122246?type=0&order=0&pos=23&page=1

Markdown Content:
秋招基本结束，写一波面经和体会回馈牛客

七月提前批
-----

科大讯飞
----

### 内推电话面

1\. 自我介绍  
2\. 介绍FashionAI项目（做了什么重要工作，有无对模型进行改进）  
3\. 问更熟悉C++还是Python（答Python）  
4\. 针对Python问了一系列的知识点：

- Python字典采用的是什么数据结构？（没答对。正解：使用的是key-value匹配的哈希结构）
- Python的列表和元组的区别？（可变 vs 不可变）
- Python的多线程能否用来做并行计算？（不能，它有GIL锁，但可以用多进程实现并行）
- 口答编程题：如何用Python统计大型单词文件的词频并返回最多的前100个单词？（想到用字典统计词频，但后面除了想到用排序没有想到其他的。网上找到的\[海量数据处理思路\](http://www.cnblogs.com/wentingtu/archive/2011/12/16/2290619.html)：散列处理（用Hash散列把大文件拆分成许多小文件使内存可以处理）+词频统计（可以使用字典进行hash-map或使用字典树Trie来统计词频）+频数排序（可用含100个结点的最小堆，每当新读取的元素比堆顶元素大，就替换堆顶元素并调整堆）+合并处理（可使用归并排序））

5\. 针对深度学习问了一系列知识点：

- 缓解过拟合的方法？（数据增强、L1/L2正则化、dropout、早期停止）
- dropout的原理？
- Batch Normalization的原理？可学习的参数有哪些？
- 自适应优化算法有哪些？（Adagrad（累积梯度平方）、RMSProp（累积梯度平方的滑动平均）、Adam（带动量的RMSProp，即同时使用梯度的一、二阶矩））
- Batch size对模型训练有什么影响？其大小是怎么选取的？（会影响训练的稳定性，Batch size过小会使Loss曲线振荡的比较大，大小一般按照2的次幂规律选择，至于为什么？没有答出来，面试官后面解释是为了硬件计算效率考虑的，海哥后来也说GPU训练的时候开的线程是2的次幂个）

6\. 感想：感觉表现的不是很好，多半没戏了。但通过此次面试被问到的一些问题，尤其是Python相关的知识点，暴露出对Python知识的一些盲点，算法和数据结构也要抓紧复习。把每一次面试都要当成是一次学习和检验的过程，不断总结提升。

7\. 后面9月下旬的时候意外接到了科大讯飞的面试通知，二面没有再问什么很难的技术问题，除了自我介绍和项目介绍，剩下就是问了些个人学习、家庭情况，最后也拿到了科大讯飞华南研究院的offer。

CVTE
----

### 提前批电话面

1\. 自我介绍  
2\. 介绍目标检测的项目（做了哪些重要的改进工作，取得的效果怎样，工作中面临的挑战或难点有哪些）

- 主要对二阶目标检测器的特征提取网络做了改进
- 在Pascal VOC数据集上的mAP达到了80%，与基于ResNet-FPN的faster R-CNN效果相当，但模型大小减小了三成；在红外图像的电力设备检测中mAP达到了85.4%比改进前提升了5.6个百分点。
- 红外图像视觉质量低、目标尺寸差异大、某些目标类间差异小

3\. 是否了解EM算法（只说了下大概的原理，用于含有隐变量的概率模型极大似然估计或最大后验概率估计的迭代算法，其它不是很了解）  
4\. 传统的图像算法熟悉吗？有哪些常用的特征？SIFT特征是如何保持旋转不变性的？（常用的图像特征HoG、SIFT等；sift特征通过将坐标轴旋转至关键点的主方向来保持旋转不变性，关键点的主方向是通过统计关键点局部邻域内像素梯度的方向分布直方图的最大值得到的）  
5\. 情景题：如何让计算机通过老师讲课的视频分析他在讲什么课

- 答的不好，只是笼统地说先用目标检测和图像识别对一帧图像进行分析，必要的话还需要结合时序对多帧图像进行分析，没有根据不同的情况进行深入地思考。
事后和实验室同学交流时，同学分析地更深入一些：首先会判断视频中老师讲课有没有使用黑板，如有会通过识别黑板上不同类型的信息进行初步的分析判断
（如比较多的数学公式很可能是在讲数学课、比较多的英文可能是在讲外语课等），如果没有或是需要更精确的判断，会再对老师讲的话等信息进行时序分析，综合判断。

6\. 感想：面完立马就在招聘官网的个人中心查到“面试未通过”，有些失落和沮丧，可能主要是在那个情景题上没有答好，还有回答一些问题的时候表述不太清楚，需要花时间去练习一下如何尽可能清晰地把自己的想法表述清楚（感觉主要原因还是没有想清楚或知识掌握不牢）

八月攻坚期
-----

华为
--

### 优招

#### 1 算法业务面

一面的面试官是个女的，感觉还是比较nice的。  
1\. 自我介绍  
2\. 介绍目标检测项目（按STAR法则详细讲了一下项目背景、研究目标、所做工作以及取得的效果）  
3\. 期间问了几个问题

- 为什么选择前面提到的那些网络模型和结构？（答：通过对课题项目面临的问题和挑战分析结合网络模型和结构的特点选择的）
- 看paper的时候一篇paper要看多久？（答：视情况而定，在文献查找和搜索的时候一般只会浏览标题和摘要，几分钟就能看一篇；在读摘要的时候发现有比较好的或有必要细读的会下载下来，
大概花1~2个小时粗读一遍，主要看introduction,Method和result；对于非常有价值的paper，会仔细反复研读，可能要花数天。其实第三点我当时没说，面试官说我看论文还挺快的，
下次要再被问到还是要说第三点，否则会让人觉得你看论文不仔细）

然后基本就差不多了，一面感觉还是比较顺利，接着面试官就让我去综合面试等候区等候二面。

#### 2 研发综合面

二面时候碰到的是个男面试官，第一眼就感觉他表情比较严肃，预感不太好。

面试官：先简单做一下自我介绍。

我：balabala~（又把自我介绍简单重复了一遍）

面试官：你平时遇到重大场合会焦虑紧张吗？是怎么应对的？

我：会有一些，碰到重大场合难免会有些焦虑紧张，通常我会通过深呼吸、心里默念一些鼓励的话或是通过与别人交谈等手段来调整。

面试官：你家里情况怎样？有兄弟姐妹吗？

我：家里情况还好，关系比较和睦，有一个姐姐。

面试官：以后想在哪里工作

我：想留在广东

面试官：为什么想留在广东？

我：因为我在广东亲戚比较多，自己也比较喜欢广东的气候，而且广东珠三角经济发达，机会比较多。（感觉应该把说的顺序调整一下，把发展机会大放在前面）

面试官：谈谈对华为的认识？

我：华为是民族企业的骄傲，从ICT业务起家并不断发展壮大，现在业务遍及全球，在5G,芯片设计，终端等领域处于世界领先水平...（总之就是把华为吹了一波）

面试官：为什么想来华为？

我：觉得华为是大企业，发展前景大，也比较认同华为拼搏奋斗的文化

面试官：怎么看待华为的加班现象？

我：可以理解，互联网行业都有加班现象，加班虽然辛苦，但也能使自己的能力得到更多的锻炼。不过，也不能一味地严重加班，弄坏了身体。

面试官：你觉得什么是人才？

我：我觉得人才不一定十全十美，但一定有自己的核心竞争力，能够通过学习和实践不断提升自己的能力和专业水平。

面试官：对于企业而言，你说的都只是人才的必要条件，而非充分条件。充分条件是人才能解决实际的问题，为企业带来利润的增长。你不能为了学习而学习，而要为解决问题而学习，在做实际的项目，解决实际问题的过程中，才能逐渐成为一名人才。（这段话很受教，前面的回答还是太学生思维了）

后面还问了一些其它问题，因为比较零散，就不一一赘述了。最后面试官问完，照例问我有什么问题。我就简单问了下华为的人才培养机制以及应聘岗位会从事的业务范围是什么。然后面试官就示意我可以离开了，后面等通知。整个二面过程下来，感觉虽然没问什么具体的技术问题，但面试官对我的感觉并不好（他可能觉得我有点不自信且没有什么主见），不管怎样，既然已经面过了，一切随缘吧！对华为不报太大希望，还是继续认真准备其它公司的面试。

VIVO视频一面
--------

1\. 自我介绍  
2\. 介绍觉得做的最好的的一个项目  
3\. 算法题：如何判断单链表中是否有环？

是个很经典的面试题，可惜没有答出来，面完后同学说了思路：用快慢指针或者哈希表。对于快慢指针方法，如果单链表存在环，快、慢指针必定会在环中的某个结点相遇；
对于哈希表方法，可以使用STL的map将链表结点指针映射成map下标，每访问过一个结点p，就将m\[p\]赋为1(m\[p\]初始为0)，若在访问某个结点时其m\[p\[已经被设为1，说明已被访问过，即有环

参见：[https://blog.csdn.net/cyuyanenen/article/details/51712420](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fblog.csdn.net%2Fcyuyanenen%2Farticle%2Fdetails%2F51712420)  
4\. 机器学习中L1和L2范数各有什么特点以及相应的原因？  
L1范数更容易产生稀疏的权重，L2范数更容易产生分散的权重，原因一般从梯度更新公式角度或者几何角度去解释，但是几何角度没有解释好

*   从**公式**角度理解：DL花书7.1节（202页左右）。带L1正则化的最优参数w=sign(w\*_) max{|w\*_|- a/H , 0}，其中w\*_代表未正则化的目标函数的最优参数，a是正则化系数，只要a足够大，w \*就会在更大区间范围内使w变为0，而带L2正则化的最优参数w=H/(H+a)_ w\*,只要w\*不为0，w也不为0.
*   从**几何空间**角度理解：绿色等高线代表未施加正则化的代价函数，菱形和圆形分别代表L1和L2正则化约束，L1-ball 与L2-ball的不同就在于L1在和每个坐标轴相交的地方都有“角”出现，而目标函数的"等高线"除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置就会产生稀疏性。相比之下，L2-ball 就没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小  
    ![Image 1](https://uploadfiles.nowcoder.com/files/20180930/450315_1538297883100_Screen-Shot-2015-08-26-at-21.56.02.png?x-oss-process=image/resize,p_74)

多益网络一面
------

1\. 自我介绍  
2\. 最好的项目介绍（讲了基于深度学习的目标检测项目，有问到模型的效果、模型大小、实时性如何以及后续进一步提升模型检测精度的想法）  
3\. 机器学习相关问题

*   常用正则化方法有哪些？（参数范数惩罚、Dropout）
*   梯度消失/爆炸是什么？（反向传播中由于链式求导法则的连乘，如果乘数都比较小趋于0，最终传递到网络输入层的梯度会变得很小（梯度消失），如果乘数都很大，最终的梯度也会变得很大（梯度爆炸），其实二者都是因为网络太深导致权值更新不稳定，本质上是因为梯度反向传播中的连乘效应）
*   LR与线性回归的区别（LR通常用于二分类，使用的是交叉熵损失函数；线性回归用于回归，使用的是均方误差损失函数）
*   SVM的原理？如何解决线性不可分问题？（间隔最大化，通过引入软间隔、核函数解决线性不可分问题）  
    4\. 数学概率题：一副扑克牌，随机均分成三份，问大小王被分到同一份的概率是多少？（一时没答上来，后面问了海哥，应该是从52个里面取16个的组合数/从54个里面取18个的组合数，按基本的计算概率的思路去算， **概率统计要加强**）  
    5\. 算法题：找出2000万条记录中出现次数最多的前十条记录

（一种思路是通过哈希散列将大文件拆分成小文件，然后对每个小文件的记录进行频数统计，取各文件频数前十的记录进行归并排序，再取最终结果的前十；更简单快捷的方法是在频数统计后依次遍历每个小文件，直接维护一个10个节点的最小堆）

6\. 问了一些非技术问题：

*   对于互联网加班怎么看？
*   学习成绩怎么样？
*   期望薪资是多少？
*   目前有拿到offer吗？

7\. 最后是一道编程题：5分钟内写出冒泡排序（因为时间短有些紧张，没完全写对，**面试时紧张和焦虑很影响发挥，需要想办法调整**）

总结：多益网络的概率题和编程题没答好，多半也没戏了，从中**暴露出的概率统计分析能力不足和抗压调节能力较差要重视起来**。对概率统计进行专项训练，学习一些克服紧张、缓解焦虑的方法，比如改变认知（降低心理预期，小事多用心、正事用点心、大事放宽心）、注意转移（分心/专注）、合理表情（微笑）、心理暗示（面试前准备幸运物，紧张时摸一摸）、生理放松（深呼吸、平时多运动、面试前休息好）、熟能生巧（多参加面试）等，详见[知乎](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F21187514%2Fanswer%2F137107187)

另外**面试前准备的时候，可以多思考一下，准备一些回答问题的要点，尽量不要准备充分的稿子，防止背不过卡壳**，才是面试成功的终极方法。

图普科技技术终面&HR面
------------

### 技术终面

1\. 自我介绍（学习能力强、善于分析解决问题、热爱生活）  
2\. 图普的深度学习谜题是怎么解出来的？（用的是减少训练类别的近似法）  
3\. 做过的最难的一个项目是什么？（介绍了电力设备检测项目，还问了后续的进一步改进想法）  
4\. FashionAI比赛你们是怎么做的？（先用目标检测技术检测出包围所有关键点的最小边界框，再在此基础上用CNN模型进行回归）  
5\. SVM懂不懂，会推公式吗？（于是用拉格朗日乘法手推了一遍SVM原始形式和对偶形式的公式）  
6\. 写出softmax分类器的交叉熵损失函数，并求对输入权重的导数（前面写出来了，后面的求导一时没有写出来,后面面试官有解释真实类别对应的输入权重的梯度比其它类别的输入权重的梯度要多减一个1，公式详见[cs231n 课程作业](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fblog.csdn.net%2Fzhangxb35%2Farticle%2Fdetails%2F55223825)）  
7\. 你有什么问题想问的？（问了一下图普的业务有没有目标检测相关的）

### HR面

HR面相对比较轻松，主要问了以下几个问题：  
1\. 你选择公司时的一些考量是什么？（我答了职业兴趣、公司的发展前景、薪酬福利、地域因素等）  
2\. 你现在找工作的进展如何？  
3\. 可以提前来实习吗？（他们对广州本地的校招应聘者一般都希望能提前去实习）  
4\. 期望薪资是多少？（自己没什么经验，说的20w+，后面问同学才知道说低了。在谈薪资的时候，只要不太离谱，一般会按照你说的开。对于初创互联网公司，可以说的高一点，它们一般为了跟大厂抢人，愿意开更高的工资）  
5\. 你有什么问题想问的？（问了大概什么时候能知道结果）

### 整体感觉

除了softmax交叉熵函数求导没答好，其它答的都还可以，拿到offer应该没问题。

腾讯社交广告部内推
---------

### 技术一面

1\. 手撕两道代码题

- 无序数组中找第k大的数
- 实现简单的NMS（已提供计算IOU的函数）

2\. 项目介绍及相关细节  
2.1 FashionAI比赛（主要介绍了自己负责的服饰边界框检测部分）

- 做了哪些模型调参工作？
- RPN是怎么训练的？
- 怎么用Mask R-CNN做服饰关键点检测的？
- Mask R-CNN相比于Faster R-CNN有哪些改进？

2.2 电力设备检测

- 是怎么解决图像细节不足问题的？（增强特征提取骨干网络的表达能力）
- DenseNet为什么比ResNet有更强的表达能力？
- SENet的Squeeze-Excitation结构是怎么实现的？
- 基于FPN的RPN是怎么训练的？（在FPN的每个预测层上都接一个RPN子网，确定RPN子网的正负anchor box样本，再计算各预测层上RPN的anchor box分类和回归损失，利用BP将梯度回传更新权值）

### 技术二面

1\. 自我介绍  
2\. 继续问项目  
2.1 汽车指示灯识别App开发

- SIFT特征是怎么生成的？(先生成尺度空间，再在尺度空间中检测局部极值点作为关键点并对关键点进行精确定位，接着确定关键点的主方向，最后根据关键点邻域的梯度信息生成特征描述符)
- SIFT特征是怎么进行匹配的？（OpenCV中常用的是暴力匹配函数，即对两组SIFT特征向量，将一组中的每个向量依次与另一组的所有向量进行欧式距离度量，选择距离最近的作为匹配点，
可以参考\[详情\](https://blog.csdn.net/dcrmg/article/details/52577555)）

3\. 一道概率相关的算法题：100块钱随机分给10个人，要求每个人分到的数额在期望上相等（即都是10）  
没太答好，只达到了一部分，即为每个人依据均值为10的高斯分布随机生成一个数，但后面可能10个人分到的数加起来不等于100。后面问面试官怎么解决才知道再用一个归一化就可以了（即如果加起来为110，那每个人分到的钱数\*10/11即可）

### 技术三面

更多的是聊了本科做过的一些项目，比如数学建模比赛还有本科毕设。此外聊了一下对其它非目标检测领域的一些知识的涉猎程度还有个人技术博客上的一些内容。

感受：求职以来经历过的最密集的面试，2个小时内面了3轮，中间几乎都没有休息，讲得口都干了。希望能继续走下去，拿到鹅厂的offer。

阶段总结
----

辛苦找了两个月，8月底的时候终于拿到了2个offer，分别是多益网络的大数据和人工智能工程师以及图普科技的深度学习工程师，总算有保底的了。

九月佛系期
-----

Bigo（百果园）机器学习(视觉方向)算法
---------------------

### 笔试题

1\. 什么是导数、偏导数、方向导数和梯度？

*   导数：函数在某点的导数是函数在该点的瞬时变化率，几何上即该点切线的斜率
*   偏导数：函数在某点沿坐标轴方向的导数
*   方向导数：函数在某点沿某一方向的导数（偏导数是方向导数沿坐标轴方向的特例）
*   梯度：梯度是一个由函数对各坐标轴的偏导数组成的向量，方向导数可以写成梯度grad和单位方向向量l的内积,故当grad与l同方向时，方向导数取得最大值，故梯度的方向时方向导数取最大值时的方向，梯度的幅值是方向导数的最大值

详细参见[方向导数、梯度](https://gw-c.nowcoder.com/api/sparta/jump/link?link=http%3A%2F%2Fmath.fudan.edu.cn%2Fgdsx%2FKEJIAN%2F%25E6%2596%25B9%25E5%2590%2591%25E5%25AF%25BC%25E6%2595%25B0%25E5%2592%258C%25E6%25A2%25AF%25E5%25BA%25A6.pdf)

2\. 分类和回归的区别，各举例3个模型

分类预测离散值输出，常见分类模型有感知机、朴素贝叶斯、逻辑回归(LR)、支持向量机(SVM)等；

回归预测连续值输出，常见回归模型有线性回归、多项式回归、岭回归（L2正则化）、Lasso回归（L1正则化）等

3\. 什么是感受野，感受野的计算公式？

CNN中的感受野是指网络中某一层的NN在输入图像中对应的感受区域大小，其计算公式  
RF_i\=RFi-1_+(k-1)×S_j-1, Sj-1_为前j-1层的步长的累乘

4\. 卷积层和全连接层的区别？

5\. LR原理和求解方法

6\. 一辆车经过p点会有50%的概率变速，速度可以是一分钟/圈或两分钟/圈。若随机时间到达p点等车，求等车时间的期望。

7\. 一道求马尔可夫链稳态概率的题

8\. 编程题:链表循环右移k位

9\. 开放题:介绍自己熟悉领域的几种算法及其insight

### 面试

1\. 介绍FashionAI比赛  
相关问题:

*   写一下比赛测评指标的公式(归一化定位误差)
*   介绍Faster R-CNN原理
*   写一下RPN的损失函数(多任务损失:二分类损失+SmoothL1损失)
*   RPN损失中的回归损失部分输入变量是怎么计算的？(注意回归的不是坐标和宽高，而是由它们计算得到的偏移量,详见[Faster R-CNN原文](https://gw-c.nowcoder.com/api/sparta/jump/link?link=http%3A%2F%2F202.38.196.91%2F***%2F2%2F03%2Fpapers.nips.cc%2Fbd3b0308f776f18fcde88fffa66f4a0e%2F5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf)
*   RPN中的anchor box是怎么选取的？
*   RoI Pooling是怎么做的？有什么缺陷？  
    2\. 机器学习相关问题
*   缓解过拟合的方法？
*   常用的正则化方法有哪些？
*   L1和L2正则化各有什么特点？为什么会有这样的特点？  
    3\. 手撕代码(笔试中没写完的题)  
    链表循环右移k位

网易(深度学习工程师）面试
-------------

1\. 简单自我介绍  
2\. 介绍FashionAI项目并问了些相关问题

- Faster R-CNN的训练过程是怎样的？
- 最后的效果怎么样？比赛排在前面的队伍结果达到了多少？

3\. 暑假有没有去实习？  
4\. 课题项目的创新点？有没有发论文？  
5\. 熟悉哪些语言？（说了python、C++，然后就C++展开问）  
6\. C++的栈区和堆区知道吗？分别是干什么用的？（栈区是存储函数内部变量的内存区，堆区是存动态申请的内存）  
7\. 什么时候要进行动态内存申请？（以前没思考过，没答上来，后来查了一下，当无法事先确定对象需要使用多少内存（这些对象所需的内存大小只有在程序运行的时候才能确定）时就要申请动态内存，比如维护一个动态增长的链表或树）  
8\. 熟悉Linux吗？如何查看某进程关联的相关文件有哪些？（这里应该自己主动说的，显得有点被动了）

YY(计算机视觉算法工程师)面试
----------------

只讲下被问住的问题  
1\. 分类中为什么交叉熵损失函数比均方误差损失函数更常用？

（交叉熵损失函数关于输入权重的梯度表达式与预测值与真实值的误差成正比且不含激活函数的梯度，而均方误差损失函数关于输入权重的梯度表达式中则含有，由于常用的sigmoid/tanh等激活函数存在梯度饱和区，使得MSE对权重的梯度会很小，参数w调整的慢，训练也慢，而交叉熵损失函数则不会出现此问题，其参数w会根据误差调整，训练更快，效果更好，[参见链接](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fwww.jianshu.com%2Fp%2Fd20e293a0d34)）

1.  Faster R-CNN是如何解决正负样本不平衡的问题？

（限制正负样本比例为1:1，如果正样本不足，就用负样本补充，这种方法后面研究工作用的不多。通常针对类别不平衡问题可以从调整样本数或修改loss weight两方面去解决，常用的方法有OHEM、OHNM、class balanced loss和Focal loss,详见[视觉分类任务中处理不平衡问题的loss比较](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fblog.csdn.net%2Fweixin_35653315%2Farticle%2Fdetails%2F78327408%23commentsedit)）

顺丰科技视觉算法工程师面试
-------------

1\. 自我介绍  
2\. 介绍项目  
3\. 深度学习中网络训练时loss不降的解决方法  
4\. make、cmake、g++这几者之间的关系  
5\. 神经网络训练时类别不平衡问题的解决方法

国企
--

除了互联网公司外，九月份还面试了两家国企和事业单位，事业单位的面试相对互联网公司来说难度要低，主要看中的是学历、成绩，也会考察一些基础知识，自己比较幸运，也都拿到了offer。

秋招总结
----

因为没有实习的原因，我准备秋招算是早的了。但前两个月也都是各种碰壁，可能也跟今年算法岗竞争激烈的行情有关。七月份提前批的时候大多投的内推，虽然多数没有笔试，但面试的时候表现并不好，自己有很多知识点都存在漏洞和不足，并没有很好地利用好提前批阶段。

八月份开始进入秋招密集期，除了继续参加一些公司的提前批面试，也开始做一些笔试，但笔试考的知识点比较多，有时还有多道编程题，想单凭一己之力做好来比较难，通常都是同学之间互帮互助。过了八月中旬的时候，我手里还是0 offer，看着身边的同学开始陆续拿到offer，自己心里越来越焦虑，但再焦虑也没有用，只能每次面试尽力去准备，把每次面试都当做一次学习的机会，面试的好固然值得高兴，面试的不好也不能过于灰心丧气，要认真分析总结暴露出的问题，避免下次再犯。当我圆满走完多益网络整个秋招提前批流程的时候终于在八月下旬收到了第一个offer，后面图普科技的offer我是因为和同学一起做出了它的谜题直通技术终面拿到的。拿到图普的offer后，自己比较满意，就把多益网络的offer给拒了。还有值得一提的是腾讯内推连面三轮，本以为希望较大，最后还是凉了，只能说与大厂无缘。

九月份找工作已经没有八月份那么焦虑不安了，这是好的一点，当然不好的一点就是没有之前那么努力认真了（如果已经找到了自己比较满意的工作这种心态是自然而然的）。陆续做了一些公司的笔试也参加了一些面试，但在互联网公司并没有拿到更多的offer。只拿到了两家国企和事业单位性质的offer。等到10月初，自己作为应届生为期三个月的秋招基本结束。总共拿到了5个offer，三家互联网公司的offer，两家国企的offer。找工作辛苦，没想到选工作也纠结。自己从自身性格特点、家人朋友建议以及打听到的一些企业信息等方面经过一番认真考虑后，最终还是选择去了国企。

以上是我三个月秋招经历的一些面经和总结，算是对自己的一次回顾，也希望能对奋斗在找工作路上的应届生有所帮助和启发，最后希望每个求职者都能找到自己满意的工作。

[#秋招#](https://www.nowcoder.com/creation/subject/002d6ce4eab1487f9cae3241b5322732)[#面经#](https://www.nowcoder.com/creation/subject/928d551be73f40db82c0ed83286c8783)[#算法工程师#](https://www.nowcoder.com/creation/subject/146d543971d045ba84b4b8a4dd573fff)[#网易#](https://www.nowcoder.com/enterprise/149/discussion)[#腾讯#](https://www.nowcoder.com/enterprise/138/discussion)[#欢聚集团#](https://www.nowcoder.com/enterprise/167/discussion)[#BIGO#](https://www.nowcoder.com/enterprise/1019/discussion)
