Title: 字节跳动2020届提前批 AI Lab cv 三面视频面_牛客网

URL Source: https://www.nowcoder.com/discuss/210508

Markdown Content:
字节跳动2020届提前批 AI Lab cv 三面视频面
----------------------------

更新：2019/8/11收到意向书
-----------------

更新：2019/8/7收到offer call
-----------------------

一面 视频面（50min）2019/7/17
----------------------

*   自我介绍
*   Kaggle的比赛大致介绍一下
*   用了哪些trick

答：循环学习率，快照融合

*   对分类，分割检测，视频理解哪方面比较熟悉？

答：对分类，分割比较熟悉

*   那我们问一下检测方面的问题吧（我：？？？），你了解faster rcnn吗，大致介绍一下
*   再问一个分割检测方面的，了解nms吗，大致介绍一下
*   模型训练过拟合怎么办

答：数据增强，增大数据量；换更大更深的网络，更好的backbone；dropout，BN等

*   BN为什么防止过拟合呢？

正确答案应该是

> 大概意思是：在训练中，BN的使用使得一个mini-batch中的所有样本都被关联在了一起，因此网络不会从某一个训练样本中生成确定的结果。

> 这句话什么意思呢？意思就是同样一个样本的输出不再仅仅取决于样本本身，也取决于跟这个样本属于同一个mini-batch的其它样本。同一个样本跟不同的样本组成一个mini-batch，它们的输出是不同的（仅限于训练阶段，在inference阶段是没有这种情况的）。我把这个理解成一种数据增强：同样一个样本在超平面上被拉扯，每次拉扯的方向的大小均有不同。不同于数据增强的是，这种拉扯是贯穿数据流过神经网络的整个过程的，意味着神经网络每一层的输入都被数据增强处理了。

> \---------------------

> 作者：qq\_23150675

> 来源：CSDN

> 原文：[https://blog.csdn.net/qq\_23150675/article/details/79452685](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fblog.csdn.net%2Fqq_23150675%2Farticle%2Fdetails%2F79452685)

> 版权声明：本文为博主原创文章，转载请附上博文链接！

但是我回答的是BN为啥work的原因，包括BN原论文解释的改善ICS现象，但是今年年初MIT的一篇论文《How Does Batch Normalizetion Help Optimization》推翻了这个结论，该论文认为

1.  BN带来的性能提升与ICS的减少无关。 并且在一定程度上认为BN并不能减少 ICS。
2.  发现了BN使得优化问题的曲面更加平滑，这使得梯度更容易预测以及允许更大范围的学习率和更快的网络vonvergence。证明了BN提升了模型的LOSS的Lipschitzness和梯度的Lipschitzness（β-smoothness）。**换个说法：**引入了 BN 后，损失函数相对于激活函数值的梯度幅值更小，也即损失函数更加利普希兹。损失函数相对于激活函数值的二阶项幅值更小，也即损失函数更加贝塔平滑。同理，损失函数相对于权重的梯度幅值也更小。 权重的最优解与初始解的距离也更小，也即神经网络更快就可以训练到最佳表现。（参考：[https://www.zhihu.com/collection/226366658?page=4](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fwww.zhihu.com%2Fcollection%2F226366658%3Fpage%3D4)）
3.  提出了除了BN外，还有其他方式同样可以达到类似平滑效应，有些甚至效果更好。

*   算法题：判断一棵树是不是完全二叉树

> 思路：

> 1\>如果树为空，则直接返回错

> 2\>如果树不为空：层序遍历二叉树

> 2.1\>如果一个结点左右孩子都不为空，则pop该节点，将其左右孩子入队列；

> 2.1\>如果遇到一个结点，左孩子为空，右孩子不为空，则该树一定不是完全二叉树；

> 2.2\>如果遇到一个结点，左孩子不为空，右孩子为空；或者左右孩子都为空；则该节点之后的队列中的结点都为叶子节点；该树才是完全二叉树，否则就不是完全二叉树；

> \---------------------

> 作者：gogogo\_sky

> 来源：CSDN

> 原文：[https://blog.csdn.net/gogogo\_sky/article/details/76223384](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fblog.csdn.net%2Fgogogo_sky%2Farticle%2Fdetails%2F76223384)

> 版权声明：本文为博主原创文章，转载请附上博文链接！

#File Name : 是否为完全二叉树.py
class Node(object):
    def \_\_init\_\_(self,val=None):
        self.val = val
        self.left = None
        self.right = None
def isCBT(head):
    if not head:
        return True
    isLeaf = False
    queue = \[\]
    queue.append(head)
    while queue:
        head = queue.pop(0)
        left = head.left
        right = head.right
        if (not left and right) or (isLeaf and (left or right)):
            # （not left） and  right 右边存在 左边不存在
            #  或者是进入到全是叶节点状态后 有左或者右
            # 这两种情况都会返回F
            return False
        if left:
            queue.append(left)
        if right:
            queue.append(right)
        if not left or not right:
            isLeaf = True
    return True
#--------------------- 
#作者：桔梗的眼泪 
#来源：CSDN 
#原文：https://blog.csdn.net/weixin\_40274123/article/details/93648891 
#版权声明：本文为博主原创文章，转载请附上博文链接！

*   while 循环里第一个判断语句解释一下
*   有什么问题

问：AI lab业务偏多还是research偏多 面试官说：都会做，比较好的一点就是公司大中台战略，本身公司的业务场景就很多，所以有很多落地的工作可以做

问：AI lab的扩招情况，发展态势？AI lab的规模？

*   你投的哪个城市，我是目前在上海工作，如果你有兴趣的话可以到上海来

二面 视频面（60min）2019/7/17
----------------------

*   自我介绍
*   实习的工作是如何改进的
*   为什么不用L1而用L2loss监督
*   sobel算子介绍一下
*   sobel核的参数为什么里面-1 -2，改变了参数后会发生什么事情？

面试官本身是想让我回答不同的参数就能实现不同的功能效果，例如高斯模糊，腐蚀，锐化，膨胀等等

*   讲一下Focal loss，它解决了一个什么东西？

答：难易样本不平衡

*   如何解决的
*   和难例挖掘OHEM有什么区别

答：1、OHEM的策略需要人工设计，而Focal loss是自适应调整样本的权重，是更优雅的解决方案， 能够达到更好的局部最优解

2、Focal loss还有阿尔法这个超参可以控制类别不平衡，而OHEM不行

> 具体参考[https://blog.csdn.net/m\_buddy/article/details/89042338](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fblog.csdn.net%2Fm_buddy%2Farticle%2Fdetails%2F89042338)

> ![Image 1](https://uploadfiles.nowcoder.com/images/20190724/85430641_1563936567847_3E073CC9FFD5D77BB409F781DE23EC6A)

*   讲一下你熟悉的优化器，说一下区别或发展史

答：只简单讲了adam和SGD，没复习到

具体参考[https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/7294671.html](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fwww.cnblogs.com%2Fljygoodgoodstudydaydayup%2Fp%2F7294671.html)

*   算法题：一个整数数组A，求Ai-Aj的最大值Max，i<j，

c++的解法及思路： [https://blog.csdn.net/fkyyly/article/details/83930343](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fblog.csdn.net%2Ffkyyly%2Farticle%2Fdetails%2F83930343)

def f(arr):
    if len(arr)==0 or len(arr)==1:
        return 0
    if len(arr)==2:
        return arr\[0\]-arr\[1\]
    p1 = 0
    p2 = 1
    max = arr\[p1\]-arr\[p2\]
    n = len(arr)
    while p2<n:
        while p2<n and arr\[p2\]<arr\[p1\]:
            if arr\[p1\]-arr\[p2\]\>max:
                max = arr\[p1\]-arr\[p2\]
            p2 += 1

        p1 = p2
        p2 += 1
    return max

*   时间复杂度空间复杂度是多少

答：**O(n)，O(1)**

*   **一个图片中心逆时针旋转30度后，求最小外接矩形长和宽，说一下有哪些解决方法**

**答：第一种初中数学，几何知识；第二种，求解仿射变换矩阵（2x3），然后和原图相乘，就得到变换后的图片，也就知道了最小外接矩形的长和宽**

**具体参考**[https://blog.csdn.net/flyyufenfei/article/details/80208361](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fblog.csdn.net%2Fflyyufenfei%2Farticle%2Fdetails%2F80208361)

*   有什么想问的

问：这个提前批的面试流程，有几面

答：至少三面，没面过的不影响正式秋招

问：老师您在公司做的什么方面呢

答：广告方面的图像，cv-ad

三面 主管面 视频面 （30min）2019/7/23
---------------------------

*   自我介绍
*   介绍一下简历上比赛经历
*   介绍一下简历上最有含金量的工作
*   1x1卷积的作用
*   经典分类网络backbone
*   讲一下inception系列
*   经典分割网络
*   没有提问环节（感觉凉了呀）

[#字节跳动#](https://www.nowcoder.com/enterprise/665/discussion)[#面经#](https://www.nowcoder.com/creation/subject/928d551be73f40db82c0ed83286c8783)[#秋招#](https://www.nowcoder.com/creation/subject/002d6ce4eab1487f9cae3241b5322732)[#算法工程师#](https://www.nowcoder.com/creation/subject/146d543971d045ba84b4b8a4dd573fff)[#计算机视觉岗#](https://www.nowcoder.com/creation/subject/7d4d0e589e5644ee9876f304b1c35762)
