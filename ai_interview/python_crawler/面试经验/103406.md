Title: 19届春招秋招面经-NLP方向_牛客网

URL Source: https://www.nowcoder.com/discuss/103406

Markdown Content:
自我介绍（这一块得准备个标准的流畅一套）  
实习时间限制  
介绍自己的专业是干什么的

亮点：  
不均衡问题如何处理？  
文本分类发展过程？  
python:  
tuples、list、dict的区别  
iterables、generator、yield的区别  
装饰器是什么 好处是什么？如何把参数传递给装饰器？  
python中有三元运算符么？  
如何检查列表为空，最好的方法。

深度学习：  
CNN 介绍 反向传播 如何做的，参数共享指的是？  
RNN 为何引出LSTM，其优缺点，解决的问题时？  
CNN的卷积核是单层的还是多层的  
NN中有哪些超参数 ， 应该如何调节这些超参数？  
Convolution、 pooling、 Normalization是卷积神经网络中十分重要的三个步骤，分别简述Convolution、 pooling和Normalization在卷积神经网络中的作用。

机器学习：  
请简要介绍下SVM  
请简要介绍下tensorflow的计算图  
欧氏距离、曼哈顿距离  
overfitting  
LR 和 SVM  
BAGGING Boosting  
Xgboost优化点  
谈谈判别式模型和生成式模型？  
各种聚类算法的优缺点 划分：K-means 层次：AGNES 密度：DBSACN 模型：EM  
Xgboost优化点、LightGBM 与XGboost 的联系及区别，是都试过了么

比赛：  
7.特征选择是怎么样的 数据是人的体检指标，看文献，然后利用数\*\*\*算、多项式组合特征，交叉验证找到使性能提高的特征  
8.类别变量是怎么弄的（xgboost可以处理类别变量、一般的是独热编码）  
9.最后发现哪些特征显著性很高

算法：  
1\. 和为定值的两个数 / 寻找和为定值的任意多个数  
2\. 如何判断两个链表相交及找到第一个相交点  
3\. 假设淘宝一天有5亿条成交数据，求出销量最高的100个商品并给出算法的时间复杂度。 寻找最小(最大)的k个数  输入n个整数，输出其中最小的k个元素。  
4\. 寻找出现一次的数字  
其他数字出现两次，寻找出现一次的一个数字 异或  
其他数字出现三次次，寻找出现一次的一个数字  用二进制相加 取余  
其他数字出现两次，寻找出现一次的两个个数字 二分法  
5.什么是平衡二叉树？  
6\. 前中后序遍历  
7\. 图的查找算法

数据不平衡的解决：  
1、上采样  
2、下采样  
3、一分类或者异常检测  
4、数据合成SMOTE  
5、加权  
6、ensemble：不平衡问题，对负样本进行采样K折，训练K个模型，然后加权融合，能提高模型的稳定性和泛化能力：  
7、评估采用auc或者F1的方式

阿里NLP面试：  
1\. 简单自我介绍  
2\. 实习时间  
3\. kaggle比赛是什么样的  
4\. tf-idf怎么做的  
5\. 为什么tf-idf char会对结果有提高？  
6\. RNN怎么做的？  
7\. glove和fasttext怎么训练的？  
8\. 词向量如何训练的？（word2vector）  
9\. word2vector为啥语义相近的词的词向量相近？怎么达到效果的？  
10\. RNN网络结构，各结构有什么作用？  
11\. LSTM输出是所有时刻的？还是最后时刻的？  
12\. auc评测指标如何计算？其他的评测指标有吗？假设阙值为0.5，如何计算这个点？  
13\. 血糖比赛怎么做的？  
14\. lgb怎样的？缺失值处理过程？特征如何做的？  
15\. 熟悉的编程语言会哪些？Java会吗？  
16\. linux 会吗？会哪些命令？  
17\. 最近看什么书？  
总结：将自己所用的RNN模型吃透，清楚每一个细节和原理。注重数据库和linux进步。

阿里蚂蚁面试：  
1\. 简单自我介绍  
2\. kaggle比赛是什么样的？ 简单介绍了下，LR,RNN  
3\. 介绍恶意评论的不均衡问题的新想法。  样本的叠加。  
4\. 样本不均衡问题的处理？ 上采样，下采样，SMOTE等，又介绍了下文本的叠加  
5\. LR,RNN 为什么选择LR?  看别人的分享，自己比较熟悉（缺点，没从算法的选择上讲解，而是从众）  
6\. 除了LR，为啥没考虑其他算法？ 尝试了不同的算法，发现LR较好。（缺点：为什么LR比较好，而不是朴素贝叶斯等等？）  
7\. 性能差异大吗？ 不大  
8\. 有没有考虑过参数调整的问题？ 答不上来了（缺点，有没有做调参去尝试）  
9\. GBDT树型结构有没有试？对xgb的理解？ xgb，GBDT的优化  
10\. 深度学习有多种，为什么采用RNN？ RNN和CNN对比，RNN对文本的时间序列的优点。  
11\. DNN,RNN,CNN的理解？ CNN在空间上，RNN在时间上，CNN比DNN多了个局部空间，池化。DNN缺少这个。（不知道讲的准不准）  
12\. RNN用什么框架实现？ keras，Tensorflow  
13\. 比赛队伍成员几个人？ 我一个人  
14\. 天池比赛特征为什么两两相处？ 开始查文献，发现相除多  
15\. 有没有尝试暴力特征组合？ 也试了，效果不好，主要重点放在异常值预测上面  
16\. lgb缺失值填充原理？ 计算损益，选择填充  
17\. sample weight 如何计算？ 通过血糖值计算的  
18\. 开发问题，有个信用卡交易表，如何判断\*\*\*？ 方法上用聚类（k-means，密度峰），特征筛选，例如刷卡地址，时间，是否具有多行的信用卡，且额度比较多  
19\. 那具体怎么算？根据特征怎么判断？  特征处理，特征筛选，花钱时间，店铺重复率等  
20\. 一堆账号，将分类为学生，不是学生？  特征验证，学校定期打钱，开户行，收货地址，消费额度，购买东西类别，火车票折扣  
21\. 还是考虑聚类的方法吗？聚类准确性会存在问题？   聚类+规则  
22\. 有没有接触过图算法？ 没有，，，  
23\. 最自豪的事？ 社会实践比较有意思  
24\. 实验室做什么的？ 水色遥感  
25\. 为啥不放到简历上？计算机，数据挖掘都是自学的是吗？ 是的，看看博客，看看视频。  
26\. 你有什么问题？  
我问了：  
你觉得我目前有哪些不足和可以进步的地方？  
整理来说，自学能力什么的都OK，但对于项目中的问题，也会思考，例如对于算法选择之类的，你思考的浅，只有你对算法深刻理解之后，才能知道如何算法选择。觉得很多人碰到问题，只是去猜测问题的可能的原因，但是却没有去深入分析和检验自己的想法。很多人都存在这样的问题。面过很多人，都是想，猜测，到这就停止了。检验自己的猜想。

总结：模型选择上不够深入，缺少实际结果的猜想和验证。

阿里蚂蚁二面：  
1\. 自我介绍  
2\. 问研究方向（随便说了说）  
3\. 说说值得说的比赛  
4\. LSTM和GRU区别  
5\. 其他的多分类方法？  
6\. kaggle比赛创新的地方  
7\. 第一次用深度学习？天池没用深度学习？  
8\. 天池样本量多少？  
9\. 不均衡样本问题  
10\. 效果不好为啥？  
11\. 特征工程  
12\. 相关性和feature importment区别  
13\. feature importment评价原理或者公式  
14\. 除了这两个比赛，有其他项目吗？ 凉  
15\. 怎么理解机器学习和深度学习的？（这里说了好多，树，深度学习，纬度等）  
16\. 为什么对计算机感兴趣？（又扯一堆）  
17\. 如何系统学习算法？  
我问：  
1.哪有不足可以进步？  
实践较多，但需要系统学习，要不然会受限于实践的范围，知识需要再积累  
2.深度学习和图算法用的多吗？  
都会用到，图多

美团1面  
1\. 研究生方向  
2\. 看过什么书籍  
3\. 平时用什么语言  
4\. 有没有用过数据库  
5\. 用什么语言操作数据库 （这里应该说Python的）  
6\. 实习时间开始和结束  
7\. 讲讲天池比赛  
8\. 你负责哪一块，做了哪些事？  
9\. 天池为啥用lightgbm？有没有做过对比？  
10\. lightgbm的原理  
11\. lightgbm与xgboost的对比  
12\. GBDT,lightgbm，xgboost对比  
13\. 讲讲GBDT的原理  
14\. boosting 的迭代规则  
15\. GBDT和adaboost区别  
16\. 只掉包，不去看底层吗？  
17\. 讲讲GBDT参数  
18\. GBDT可以算特征重要性吗？  
我问  
1.为啥没问kaggle比赛内容？  
2.表现不好的点？  
挺不错，一些算法细节需要推敲，先这样，有消息再通知你

CVTE  
1\. 介绍体现个人亮点的笔试  
2\. 为什么大家的结果比较集中  
3\. 网络结构  
4\. RNN的节点激活函数  
5\. LR的原理，损失函数  
6\. 比赛的收获如何应用在实际项目上？  
7\. 不足的地方

谷露软件  
1\. 学过的课程，接触Python多久了  
2\. 数据结构和算法这块怎么样？  
3\. 谈一下kaggle比赛  
4\. 10万样本如何训练？  
5\. 你有尝试深度学习方法去做其他的自然语言任务？  
6\. 如何比较文本的相似度？（协同过滤相似度，余弦相似度，tf-idf相似度，深度学习词向量计算）  
7\. 一亿条文本，新的语句，判断最相似语句（哈夫曼编码判断，树结构解决）  
8\. LSTM结构和优势  
9\. 神经网络基础算法，前馈传播等有实现过吗  
10\. 看过什么论文吗？  
11\. seq2seq看过吗

oppo  
1\. 机器学习面试：lstm几个门  
2\. lstm与gru对比  
3\. 快速排序，多种排序对比  
4\. 局部变量和全局变量存在哪里  
5\. word2vector 降纬思想如何实现的  
6\. 朴素贝叶斯的思想和推导

网易  
1\. 介绍项目  
2\. 分词算法有哪些？维特比知道吗  
3\. 隐马尔可夫知道吗  
4\. 新词发现怎么做的  
5\. lstm结构  
6\. 让你做投诉里面投诉不是正品率怎么做  
7\. 聚类怎么聚  
8\. 讲一下kmeans  
9\. seq2seq结构图

二面  
1\. 新词发现原理  
2\. 多少新词，多少旧词  
3\. lstm结构和公式  
4\. 二分查找  
5\. seq2seq  
6\. 如何做文本摘要
