{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.5000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([-0.1, 0, 0.5, 1, 1.1])\n",
    "a.clamp(0, 1)  # tensor([0.0, 0.5, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1., 2., 3.],\n",
       "           [4., 5., 6.],\n",
       "           [7., 8., 9.]]]]),\n",
       " tensor([[[[1., 1., 2., 2., 3., 3.],\n",
       "           [1., 1., 2., 2., 3., 3.],\n",
       "           [4., 4., 5., 5., 6., 6.],\n",
       "           [4., 4., 5., 5., 6., 6.],\n",
       "           [7., 7., 8., 8., 9., 9.],\n",
       "           [7., 7., 8., 8., 9., 9.]]]]),\n",
       " tensor([[[[1., 1., 1., 2., 2., 2., 3., 3., 3.],\n",
       "           [1., 1., 1., 2., 2., 2., 3., 3., 3.],\n",
       "           [1., 1., 1., 2., 2., 2., 3., 3., 3.],\n",
       "           [4., 4., 4., 5., 5., 5., 6., 6., 6.],\n",
       "           [4., 4., 4., 5., 5., 5., 6., 6., 6.],\n",
       "           [4., 4., 4., 5., 5., 5., 6., 6., 6.],\n",
       "           [7., 7., 7., 8., 8., 8., 9., 9., 9.],\n",
       "           [7., 7., 7., 8., 8., 8., 9., 9., 9.],\n",
       "           [7., 7., 7., 8., 8., 8., 9., 9., 9.]]]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "a = torch.tensor([\n",
    "    [\n",
    "        [\n",
    "            [1, 2, 3],\n",
    "            [4, 5, 6],\n",
    "            [7, 8, 9]\n",
    "        ]\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "up1 = nn.Upsample(scale_factor=1, mode='nearest')\n",
    "up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "up3 = nn.Upsample(scale_factor=3, mode='nearest')\n",
    "\n",
    "up1(a), up2(a), up3(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point(x=1, y=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Point = namedtuple('Point', ['x', 'y'])\n",
    "Point(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      5\u001b[0m ])\n\u001b[0;32m----> 7\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([\n",
    "    [2, 3]\n",
    "])\n",
    "\n",
    "a.repeat(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "a.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7071)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "a = torch.tensor([\n",
    "    [1, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "b = torch.tensor([\n",
    "    [1, 0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "nn.CosineSimilarity(dim=0)(a[0], b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ConvNet(\n",
       "   (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "   (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "   (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "   (fc4): Linear(in_features=10, out_features=2, bias=True)\n",
       "   (feature): Sequential(\n",
       "     (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       " ),\n",
       " [Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)),\n",
       "  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       "  Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)),\n",
       "  Linear(in_features=576, out_features=120, bias=True),\n",
       "  Linear(in_features=120, out_features=84, bias=True),\n",
       "  Linear(in_features=84, out_features=10, bias=True),\n",
       "  Linear(in_features=10, out_features=2, bias=True),\n",
       "  Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc4 = nn.Linear(10, 2)\n",
    "\n",
    "        self.feature = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.pool,\n",
    "            self.conv2,\n",
    "            self.pool\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet()\n",
    "model, list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'123' in ['123', '1234']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 479, (720, 479))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img_path = './data/content.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img.width, img.height, img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, (2, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    return 1, tuple((2, 3))\n",
    "\n",
    "\n",
    "a, b = test()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2])\n",
    "type(a[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.23606798],\n",
       "       [5.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "# 将矩阵 a 单位化处理\n",
    "np.linalg.norm(a, axis=1, keepdims=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
