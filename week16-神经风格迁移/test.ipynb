{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.5000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([-0.1, 0, 0.5, 1, 1.1])\n",
    "a.clamp(0, 1)  # tensor([0.0, 0.5, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1., 2., 3.],\n",
       "           [4., 5., 6.],\n",
       "           [7., 8., 9.]]]]),\n",
       " tensor([[[[1., 1., 2., 2., 3., 3.],\n",
       "           [1., 1., 2., 2., 3., 3.],\n",
       "           [4., 4., 5., 5., 6., 6.],\n",
       "           [4., 4., 5., 5., 6., 6.],\n",
       "           [7., 7., 8., 8., 9., 9.],\n",
       "           [7., 7., 8., 8., 9., 9.]]]]),\n",
       " tensor([[[[1., 1., 1., 2., 2., 2., 3., 3., 3.],\n",
       "           [1., 1., 1., 2., 2., 2., 3., 3., 3.],\n",
       "           [1., 1., 1., 2., 2., 2., 3., 3., 3.],\n",
       "           [4., 4., 4., 5., 5., 5., 6., 6., 6.],\n",
       "           [4., 4., 4., 5., 5., 5., 6., 6., 6.],\n",
       "           [4., 4., 4., 5., 5., 5., 6., 6., 6.],\n",
       "           [7., 7., 7., 8., 8., 8., 9., 9., 9.],\n",
       "           [7., 7., 7., 8., 8., 8., 9., 9., 9.],\n",
       "           [7., 7., 7., 8., 8., 8., 9., 9., 9.]]]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "a = torch.tensor([\n",
    "    [\n",
    "        [\n",
    "            [1, 2, 3],\n",
    "            [4, 5, 6],\n",
    "            [7, 8, 9]\n",
    "        ]\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "up1 = nn.Upsample(scale_factor=1, mode='nearest')\n",
    "up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "up3 = nn.Upsample(scale_factor=3, mode='nearest')\n",
    "\n",
    "up1(a), up2(a), up3(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point(x=1, y=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Point = namedtuple('Point', ['x', 'y'])\n",
    "Point(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      5\u001b[0m ])\n\u001b[0;32m----> 7\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([\n",
    "    [2, 3]\n",
    "])\n",
    "\n",
    "a.repeat(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "a.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7071)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "a = torch.tensor([\n",
    "    [1, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "b = torch.tensor([\n",
    "    [1, 0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "nn.CosineSimilarity(dim=0)(a[0], b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ConvNet(\n",
       "   (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "   (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "   (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "   (fc4): Linear(in_features=10, out_features=2, bias=True)\n",
       "   (feature): Sequential(\n",
       "     (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       " ),\n",
       " [Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)),\n",
       "  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       "  Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)),\n",
       "  Linear(in_features=576, out_features=120, bias=True),\n",
       "  Linear(in_features=120, out_features=84, bias=True),\n",
       "  Linear(in_features=84, out_features=10, bias=True),\n",
       "  Linear(in_features=10, out_features=2, bias=True),\n",
       "  Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc4 = nn.Linear(10, 2)\n",
    "\n",
    "        self.feature = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.pool,\n",
    "            self.conv2,\n",
    "            self.pool\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet()\n",
    "model, list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'123' in ['123', '1234']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 479, (720, 479))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img_path = './data/content.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img.width, img.height, img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, (2, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    return 1, tuple((2, 3))\n",
    "\n",
    "\n",
    "a, b = test()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2])\n",
    "type(a[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.23606798],\n",
       "       [5.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "# 将矩阵 a 单位化处理\n",
    "np.linalg.norm(a, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"Hook called for module: {module}\")\n",
    "    print(f\"Input shape: {tuple(input[0].shape)}\")\n",
    "    print(f\"Output shape: {tuple(output.shape)}\")\n",
    "\n",
    "\n",
    "model.fc1.register_forward_hook(hook_fn)\n",
    "\n",
    "input_tensor = torch.randn(32, 10)\n",
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "a.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 2\n",
    "\n",
    "x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "a = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "a.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model 必须能被 num_heads 整除\"\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads  # 每个头的维度\n",
    "\n",
    "        # 定义线性层\n",
    "        self.linear_q = nn.Linear(d_model, d_model)\n",
    "        self.linear_k = nn.Linear(d_model, d_model)\n",
    "        self.linear_v = nn.Linear(d_model, d_model)\n",
    "        self.linear_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "\n",
    "        # 线性变换并拆分成多头\n",
    "        Q = self.linear_q(x).view(batch_size, seq_length,\n",
    "                                  self.num_heads, self.d_k)\n",
    "        K = self.linear_k(x).view(batch_size, seq_length,\n",
    "                                  self.num_heads, self.d_k)\n",
    "        V = self.linear_v(x).view(batch_size, seq_length,\n",
    "                                  self.num_heads, self.d_k)\n",
    "\n",
    "        # 调整维度以便计算注意力\n",
    "        Q = Q.transpose(1, 2)  # [batch_size, num_heads, seq_length, d_k]\n",
    "        K = K.transpose(1, 2)\n",
    "        V = V.transpose(1, 2)\n",
    "\n",
    "        # 计算注意力分数\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.d_k ** 0.5)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        attention = self.dropout(attention)\n",
    "\n",
    "        # 计算注意力输出\n",
    "        # [batch_size, num_heads, seq_length, d_k]\n",
    "        x = torch.matmul(attention, V)\n",
    "\n",
    "        # 拼接多头并通过线性层\n",
    "        x = x.transpose(1, 2).contiguous().view(\n",
    "            batch_size, seq_length, d_model)\n",
    "        x = self.linear_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 2\n",
    "    seq_length = 5\n",
    "    d_model = 512\n",
    "    num_heads = 8\n",
    "\n",
    "    x = torch.randn(batch_size, seq_length, d_model)\n",
    "    self_attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "    output = self_attn(x)\n",
    "    print(output.shape)  # 输出: torch.Size([2, 5, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ฉ', 'ั', 'น', 'ร', 'ั', 'ก', 'ค', 'ุ', 'ณ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = 'ฉันรักคุณ'\n",
    "list(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ฉ', 'ั', 'น']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list('ฉัน')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
