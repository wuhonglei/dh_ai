{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "café\n",
      "c\n",
      "a\n",
      "f\n",
      "e\n",
      "́\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cafe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "result = ''\n",
    "name_asc2 = unicodedata.normalize('NFD', 'café')\n",
    "# 将拉丁字母和重音符号组合成一个单字符\n",
    "print(name_asc2)\n",
    "for c in name_asc2:\n",
    "    print(c)\n",
    "\n",
    "unicodedata.normalize('NFD', 'café').encode(\n",
    "    'ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafe'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "# 设置一个全局变量all_letters\n",
    "# 保存了训练数据中全部可能出现的字符\n",
    "# 包括英文的大小写，加上空格、点、逗号、分号、引号等标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "\n",
    "# 实现一个unicode转Asc2码的函数，这个函数的主要作用是，将拉丁字符转为英文字符\n",
    "# 在未来在训练的时候，我们只关注英文单词中的大小写字符\n",
    "# 一些语言中的特殊字符，会直接转为英文的大小\n",
    "\n",
    "\n",
    "def unicode_to_asc2(name):\n",
    "    result = \"\"  # 保存转换后的结果\n",
    "    # 对输入的name进行标准化\n",
    "    name_asc2 = unicodedata.normalize('NFD', name)\n",
    "    # 遍历标准化后的字符串中的字符\n",
    "    for c in name_asc2:\n",
    "        # 如果字符c不是词素记号，例如不是重音符号，并且c还是英文字符\n",
    "        if unicodedata.category(c) != 'Mn' and c in all_letters:\n",
    "            result += c  # 将c添加到结果中\n",
    "    return result  # 返回结果\n",
    "\n",
    "\n",
    "unicode_to_asc2('café')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "pattern = re.compile(f'[^{all_letters}]')\n",
    "pattern.sub('', 'café')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 2, 3]])\n",
    "b = torch.tensor([[4, 5, 6]])\n",
    "\n",
    "torch.concat((a, b), dim=1)\n",
    "\n",
    "torch.rand((10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 20, 20])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "confusion = np.array([[20, 5, 5],\n",
    "                      [5, 15, 0],\n",
    "                      [5, 0, 15]])\n",
    "\n",
    "confusion.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ = {\n",
    "    'a': 1,\n",
    "    'b': 2\n",
    "}\n",
    "\n",
    "list(dict_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "total_loss = torch.tensor(0.0, dtype=torch.float32)\n",
    "total_loss += torch.tensor(2.0, dtype=torch.float32)\n",
    "total_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
